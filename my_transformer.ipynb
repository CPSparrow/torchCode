{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. 导入所需要的模块并设置语料的路径",
   "id": "be62bfcc8596d12c"
  },
  {
   "cell_type": "code",
   "id": "550baeb6bb0a4595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T05:01:40.796213Z",
     "start_time": "2024-09-24T05:01:39.647818Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "en_name = './corpus/train/EN.txt'\n",
    "cn_name = './corpus/train/CN.txt'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. 从文件中读取数据并且使用jieba分词，随后生成词表",
   "id": "d355ef4ffc27b817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T05:01:42.650748Z",
     "start_time": "2024-09-24T05:01:42.643956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def file2tokens(file_name):\n",
    "    r\"\"\"\n",
    "    :param file_name: \n",
    "    :return : tokens in lists\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = file.read()\n",
    "        data = data.split('\\n')\n",
    "        data = [list(jieba.cut(t)) for t in data]\n",
    "        data = [t for t in data if len(t) > 5]\n",
    "        return data, max([len(i) for i in data])\n",
    "\n",
    "\n",
    "def tokens2vocab(data, target=None):\n",
    "    r\"\"\"\n",
    "    根据分词后的文本生成对应的词表(vocab)和相关数据\n",
    "    :param data:generated by file2tokens\n",
    "    :param target: should be 'tgt' or 'src'\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if target == 'src':\n",
    "        vocab = {'P': 0}\n",
    "        for sentence in data:\n",
    "            for token in sentence:\n",
    "                if not token in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "        idx2token = {i: t for i, t in enumerate(vocab)}\n",
    "        vocab_size = len(vocab)\n",
    "    elif target == 'tgt':\n",
    "        vocab = {'P': 0, 'S': 1, 'E': 2}\n",
    "        for sentence in data:\n",
    "            for token in sentence:\n",
    "                if not token in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "        idx2token = {i: t for i, t in enumerate(vocab)}\n",
    "        vocab_size = len(vocab)\n",
    "    else:\n",
    "        raise ValueError(\"invalid param about target!\")\n",
    "    return vocab, idx2token, vocab_size"
   ],
   "id": "36436675051a50c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. 生成transformer使用的Tensor序列",
   "id": "bcd9e317e8bde32c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T05:05:37.581812Z",
     "start_time": "2024-09-24T05:05:37.572612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_data(token_lists: (list, list), size: (int, int)):\n",
    "    r\"\"\"\n",
    "    把分词后的文本转化成下标序列。本函数同时实现了padding的功能。\n",
    "    \n",
    "    :param token_lists:输入由file2tokens生成的src_tokens和tgt_tokens\n",
    "    :param size: \n",
    "    :return: [LongTensor, LongTensor, LongTensor]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "src_tokens, src_max_len = file2tokens(en_name)\n",
    "src_vocab, idx2src, src_vocab_size = tokens2vocab(src_tokens, 'src')\n",
    "print(src_max_len)"
   ],
   "id": "ac2e2a5ce96e0142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "bec01d8eacf2749c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
